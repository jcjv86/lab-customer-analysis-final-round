{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb30978-7781-4a98-8435-1ee2fff1b62b",
   "metadata": {},
   "source": [
    "<h1>Lab | Customer Analysis Round 1<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90072ad6-f307-495b-9b61-17f285e838ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e19e8c-13c5-47c1-bee1-705bf8e8f914",
   "metadata": {},
   "source": [
    "\n",
    "**Read the three files into python as dataframes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ad28f-293e-40f7-93c9-9380acfe81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = pd.read_csv('./files_for_lab/csv_files/file1.csv')\n",
    "file2 = pd.read_csv('./files_for_lab/csv_files/file2.csv')\n",
    "file3 = pd.read_csv('./files_for_lab/csv_files/file3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbf429-8cdd-46bb-9ada-4cf681df8ed0",
   "metadata": {},
   "source": [
    "\n",
    "**Show the DataFrame's shape.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e66df1e-2228-4f66-b5bc-25a916955182",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(file1.head())\n",
    "file1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e15108-b4aa-4898-9695-e8ddad099e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(file2.head())\n",
    "file2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d4c80-933f-4db7-a8d9-65a2a5fc2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(file3.head())\n",
    "file3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f6868-771b-47b7-8960-fe3718f3d06c",
   "metadata": {},
   "source": [
    "\n",
    "**Standardize header names.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb516d-b6d6-4641-84c5-872f388a601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.columns = file1.columns.str.replace(' ', '_')\n",
    "col1 = []\n",
    "for column in file1.columns:\n",
    "    col1.append(column.lower())\n",
    "file1.columns = col1\n",
    "    \n",
    "file2.columns = file2.columns.str.replace(' ', '_')\n",
    "col2 = []\n",
    "for column in file1.columns:\n",
    "    col2.append(column.lower())\n",
    "file2.columns = col2\n",
    "    \n",
    "file3.columns = file3.columns.str.replace(' ', '_')\n",
    "file3.rename(columns = {'State':'st'}, inplace = True)\n",
    "col3 = []\n",
    "for column in file3.columns:\n",
    "    col3.append(column.lower())\n",
    "file3.columns = col3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b8be4-7e99-4f45-98d6-f870ce1d8806",
   "metadata": {},
   "source": [
    "\n",
    "**Rearrange the columns in the dataframe as needed**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117cb6b6-eed3-46d2-8548-0546d6452370",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d361d08-5522-4fb4-8a4d-05af0afa0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aadcdc-d01d-4af7-8480-6f569d6546e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d2da1-7295-4381-b696-beabb22a7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = file2[['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca49c03-367e-484c-a5e4-857b09082c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = file3[['customer', 'st', 'gender', 'education', 'customer_lifetime_value', 'income', 'monthly_premium_auto', 'number_of_open_complaints', 'policy_type', 'vehicle_class', 'total_claim_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52233c6b-85c1-4b98-8efe-0a3218be78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a155b-fc15-472b-a7f3-42a63bdd20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813e74a-169e-427c-86a1-b771401cce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b113148-6210-4929-90c1-686c9d128515",
   "metadata": {},
   "source": [
    "\n",
    "**Concatenate the three dataframes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dda2d9-c778-45d2-8a11-420c2cf84609",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([file1, file2, file3], axis=0)\n",
    "display(data.head())\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e6678-ae6a-4fc2-a3ea-23570f4b3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a421e-0161-4311-ba1a-92db4f9c6424",
   "metadata": {},
   "source": [
    "\n",
    "**Which columns are numerical?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc122e0c-4754-4aeb-882f-7d63e5f7b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2c45b-67a2-4a97-86e0-fcc1a9db0b02",
   "metadata": {},
   "source": [
    "**Which columns are categorical**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ae216-634b-4af6-9af0-c0dd731fdfca",
   "metadata": {},
   "source": [
    "Categorical variables represent types of data which may be divided into groups. Examples of categorical variables are race, sex, age group, and educationalÂ level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0caff-a7ed-43fa-9c95-a37b1c814dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cathegorical_data = data[['st', 'gender', 'education', 'policy_type', 'vehicle_class']]\n",
    "display(cathegorical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d30da3-f57a-499d-aed6-26e82a5e0d83",
   "metadata": {},
   "source": [
    "**Understand the meaning of all columns**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc24e9-d1c1-40d0-b284-c20e1e1b9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer: customer reference\n",
    "#st: state\n",
    "#gender: gender of the customer\n",
    "#education: educational level of the customer\n",
    "#customer lifetime value: estimation of the amount of revenue a customer will generate over the course of their relationship with the brand.\n",
    "#income: income of the customer\n",
    "#monthly_premium_auto: amount customer pays to insurance company on a regular basis, often every month or every six months, in exchange for insurance coverage.\n",
    "#number_of_open_complaints: unsure, could be internal info or data be corrupt.\n",
    "#policy_type: as it states, type of policy depending on the car type (in this dataframe: personal, corporate or special).\n",
    "#vehicle_class: see below as there are 9 types\n",
    "#total_claim_amount: This is the dollar amount an insurance company paid for damages to or replacement of an insured vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719284b-5c53-4a72-854e-883a9a941378",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vehicle_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a4223-60a5-4f8f-9c99-ef92d8949865",
   "metadata": {},
   "source": [
    "#**Perform the data cleaning operations mentioned so far in class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286f940-e340-4279-bdf4-57a83ec7b080",
   "metadata": {},
   "source": [
    "**Delete the column education and the number of open complaints from the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253059c-9a15-4db7-a234-8d0cc6a1c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['education', 'number_of_open_complaints'], axis=1)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5f2b0-6e2d-4db5-8a75-498cf17df97d",
   "metadata": {},
   "source": [
    "**Correct the values in the column customer lifetime value. They are given as a percent, so multiply them by 100 and change dtype to numerical type.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2795455-2f79-4705-bbdb-0358d0e345c3",
   "metadata": {},
   "source": [
    "**Correction: they have to be divided by 100, not multiplied by**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd81fd-9e73-448f-ba88-e28c8fb33e30",
   "metadata": {},
   "source": [
    "**I will create a copy of data for later, to check which data correction for numbers method is better.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0522d9-9fdd-4e6e-b50a-4f404be862f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0dfbc-7a04-4f23-9bdc-5512a089c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa7dc0-1dd3-4ee1-b010-3928b05e8f0e",
   "metadata": {},
   "source": [
    "**METHOD 1: FUNCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d9791-4089-49f5-9d5d-cd23e526e151",
   "metadata": {},
   "source": [
    "First we get rid of the % sign and make sure to convert all to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b19a8-d3f5-4c77-8c1b-437c6d64478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_customer_lifetime_value(x):\n",
    "    if type(x) == str:\n",
    "        x = x.replace('%', '')\n",
    "    return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca392dc-6bd3-45fe-b4dc-6e1f053ce2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_customer_lifetime_value('5%') #Checking if function works as planned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a37c2-43da-49e4-beb1-d781dedf6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['customer_lifetime_value'] = data['customer_lifetime_value'].apply(clean_customer_lifetime_value)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca89e00-e2e6-4088-b8c3-46f74910113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c5b61-c7b5-41df-a495-bb206c6993dc",
   "metadata": {},
   "source": [
    "**We can clearly see that they have been converted to float successfully.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2bed14-aa3d-4dd8-ba38-d9c0be086a6d",
   "metadata": {},
   "source": [
    "**Second method: using pd.to_numeric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c424a2-6919-48a9-8801-fafcf9c3348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_numeric function - if the data is not so much corrupted, can be avoided as it can potentially create more NaN values.\n",
    "data_copy['customer_lifetime_value'] =  pd.to_numeric(data_copy['customer_lifetime_value'], errors='coerce')\n",
    "display(data_copy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db78322-ca73-4e8b-b0c1-60f279802679",
   "metadata": {},
   "source": [
    "We compare this with the use of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa03ccc-79e1-4bda-a5ae-019ae1334dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['customer_lifetime_value'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c1e76-7e9b-4ca5-9220-22d0d783fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['customer_lifetime_value'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1471fb2-1917-45cf-a54c-5358b18fe2a8",
   "metadata": {},
   "source": [
    "**We can clearly see that pd.to_numeric function creates many NaN values (almost 2k for this dataseries). We will stick to the function method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51747a9f-91ac-4153-81ed-11add33c3a1d",
   "metadata": {},
   "source": [
    "Once we have cleared the data and converted them to float, we can divide all the values in the column by 100 and round the result to 2 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91962d-2b93-456f-945d-c985bab43264",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['customer_lifetime_value'] = round(data['customer_lifetime_value']/100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd430ac-8a77-4fd4-b5cf-19a3b7e0e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c74d9-36a3-4c94-9082-7a3104096d22",
   "metadata": {},
   "source": [
    "**Check for duplicate rows in the data and remove if any.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954bf604-8988-46a4-89c3-510716c6ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "display(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223fb798-ace9-4555-8d7e-2aacc997a6b3",
   "metadata": {},
   "source": [
    "**Filter out the data for customers who have an income of 0 or less.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3118ded-2374-4e0b-8d0f-b2ffafbcc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['income']>0)]\n",
    "display(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9a307-4ad9-4c9f-b3d9-446f1aeb2805",
   "metadata": {},
   "source": [
    "<h1>Lab | Customer Analysis Round 2<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ffba7-7910-4768-8f34-4119f79d7ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "data = pd.read_csv('./files_for_lab/csv_files/marketing_customer_analysis_lab2.csv')\n",
    "display(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755efd8-22f9-492e-be65-6605c5ca6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data = data.drop([data.columns[0]], axis=1) # Dropped unname column as it is irrelevant\n",
    "data = data.drop([data.columns[3]], axis=1) #Dropped Response column\n",
    "data = data.drop([data.columns[-1]], axis=1) #Dropped vehicle type since the data is massively corrupted\n",
    "data = data.drop([data.columns[-6]], axis=1) #Dropped policy column as it has the same info as Policy Type\n",
    "data = data.drop([data.columns[-8]], axis=1) #Dropped number_of open complaints as it is non relevant\n",
    "#Since the column drops modify the columns indexes, we need to consider them in order to remove the desired ones.\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af34c2-22e6-43dd-8eab-14d5dd23a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultimate_data_cleaner(df):\n",
    "    #shape\n",
    "    print(\"Shape: \", df.shape, \"\\n\")\n",
    "    #standardize headers\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        cols.append(col.lower().replace(' ', '_'))\n",
    "    df.columns = cols\n",
    "    print(\"The new headers are: \\n\", cols, \"\\n\")\n",
    "    #displays the numerical columns\n",
    "    numerical = df.select_dtypes(np.number)\n",
    "    print(\"The numerical columns are: \\n\")\n",
    "    display(numerical)\n",
    "    #which columns are cathegorical? Therefore non numerical\n",
    "    categorical = df.select_dtypes(object)\n",
    "    print(\"The categorical columns are: \\n\")\n",
    "    display(categorical)\n",
    "    #Rounding up total claim amount and customer lifetime value columns to 2 decimals\n",
    "    df['total_claim_amount'] = df['total_claim_amount'].round(decimals = 2)\n",
    "    df['customer_lifetime_value'] = df['customer_lifetime_value'].round(decimals = 2)\n",
    "    #Dealing with NaN values - we decided to fill in vehicle class and vehicle size with the mode values.\n",
    "    df['vehicle_class'] = df['vehicle_class'].fillna(df['vehicle_class'].mode()[0])\n",
    "    df['vehicle_size'] = df['vehicle_size'].fillna(df['vehicle_size'].mode()[0])\n",
    "    #Adding a column with the month inside \"effective_to_date\" column:\n",
    "    df['month'] = pd.DatetimeIndex(df['effective_to_date']).month\n",
    "    print(\"\\nThis is the fully transformed dataframe: \\n\")\n",
    "    display(df)\n",
    "    print(\"\\nThis is the information for the first quarter: \\n\")\n",
    "    display(df[(df['month'] <=3)])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc8314-8ea8-46ae-b2e1-7a50ab063721",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ultimate_data_cleaner(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032b33c-29aa-4a56-93be-13caaedcbdb0",
   "metadata": {},
   "source": [
    "**Dealing with NaN values - Considerations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c9b252-71fa-45d8-964d-54fabc2ed4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() #Some data for context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac64f82-7683-4f60-ae25-592f3ec3aeca",
   "metadata": {},
   "source": [
    "Should we get rid of the income 0 and unemployed rows? Running a comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900d9c6-d147-41a3-9fd8-0afa01b44b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = data[(data['income'] > 0) & (data['employmentstatus'] !='Unemployed')]\n",
    "nojobs = data[(data['income'] == 0) & (data['employmentstatus'] =='Unemployed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12a1fc-9376-4313-8af2-bfa0b18c2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(jobs.shape)\n",
    "display(nojobs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deaaf90-9a9b-4e96-8f9a-a5a37a0e6045",
   "metadata": {},
   "source": [
    "We can clearly see that the number of unemployed and also income 0 customers is bvery significant. Some may even have high customer values and expensive policies, so as long as they pay their quotas they are relevant data. We will not get rid of these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbb660-4dc6-4022-811b-2b402d1a190e",
   "metadata": {},
   "source": [
    "We can consider to fill out Vehicle Size and Vehicle Class NaN values, since they are around 600 (6% of the total). Since we are talking about a categorical value, we cannot use mean or median to fill them out, so we have used the mode. We have done this with the function already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22e430-592f-4ae6-bb35-971b96f99ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vehicle_size'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066cfa15-91ab-43ab-bc72-8a951398a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vehicle_class'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5c623-aa4c-4c30-98c8-6886dff01f21",
   "metadata": {},
   "source": [
    "**There are no longer NaN values on both columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb865fe-0d52-4f5f-9a3b-dfd35eeb8bd9",
   "metadata": {},
   "source": [
    "**Datetime format - Extract the months from the dataset and store in a separate column. Then filter the data to show only the information for the first quarter , ie. January, February and March. Hint: If data from March does not exist, consider only January and February.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374b0b20-c465-4160-8904-8e532c9e7ce0",
   "metadata": {},
   "source": [
    "Done previously with the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489b09b-f706-4f06-b0aa-87a4bd99fba9",
   "metadata": {},
   "source": [
    "<h1>Lab | Customer Analysis Round 3<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e59e46-24f9-48f0-8a8d-6a379a7027c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "data = pd.read_csv('./files_for_lab/csv_files/marketing_customer_analysis_lab3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f67da9-d5ab-46d6-bb5d-2a9ab54ed65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labs3_graphs_data(df):\n",
    "    df = data.drop_duplicates()\n",
    "    df = data.reset_index(drop = True)\n",
    "    print('This is the original dataframe as loaded from the .csv file')\n",
    "    display(data)\n",
    "    print('These are the original Dataframe column names')\n",
    "    display(data.columns)\n",
    "    #Standardize headers\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        cols.append(col.lower().replace(' ', '_'))\n",
    "    df.columns = cols\n",
    "    #Rounding up total claim amount and customer lifetime value columns to 2 decimals\n",
    "    df['total_claim_amount'] = df['total_claim_amount'].round(decimals = 2)\n",
    "    df['customer_lifetime_value'] = df['customer_lifetime_value'].round(decimals = 2)\n",
    "    #Displaying Df info\n",
    "    print(\"This is the dataframe info: \\n\")\n",
    "    display(data.info())\n",
    "    #Describe Df\n",
    "    print(\"This is the dataframe description: \\n\")\n",
    "    display(df.describe())\n",
    "    fig, axes = plt.subplots(2,2, figsize=(10,8), dpi=200)\n",
    "    #Total responses\n",
    "    sns.histplot(data=df, x='response', hue='response', ax = axes[0,0])\n",
    "    axes[0,0].set_xlabel('Response')\n",
    "    axes[0,1].set_ylabel('')\n",
    "    axes[0,0].set_title('Total Responses (%)')\n",
    "    #Sales channel VS response\n",
    "    sns.histplot(data=df, x='response', hue='sales_channel', ax = axes[0,1])\n",
    "    axes[0,1].set_xlabel('Response')\n",
    "    axes[0,1].set_ylabel('')\n",
    "    axes[0,1].set_title('Sales Channel VS response')\n",
    "    #Total claim amount VS Response\n",
    "    sns.histplot(data = df, x='total_claim_amount', hue='response', ax = axes[1,0])\n",
    "    axes[1,0].set_xlabel('Total claim amount')\n",
    "    axes[1,0].set_ylabel('')\n",
    "    axes[1,0].set_title('Total claim amount VS Response')\n",
    "    #Response VS income\n",
    "    sns.histplot(data = df, x='income', hue='response', ax = axes[1,1])\n",
    "    axes[1,1].set_xlabel('Income')\n",
    "    axes[1,1].set_ylabel('')\n",
    "    axes[1,1].set_title('Income VS Response')\n",
    "    plt.tight_layout()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e591292-84b6-454a-85f5-2043ace17e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs3_graphs_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c5e63-0862-469e-bfff-f1dc7e6a4997",
   "metadata": {},
   "source": [
    "<h1>Lab | Customer Analysis Round 4<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b8657-172a-4f22-90d7-23c1ece8d0ab",
   "metadata": {},
   "source": [
    "Check the data types of the columns. Get the numeric data into dataframe called numerical and categorical columns in a dataframe called categoricals. (You can use np.number and np.object to select the numerical data types and categorical data types respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd14c88-6b5d-4e42-96aa-5e96e88be43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_4(df):\n",
    "    df = data.drop_duplicates()\n",
    "    df = data.reset_index(drop = True)\n",
    "    print('This is the original dataframe as loaded from the .csv file:')\n",
    "    display(data)\n",
    "    print('\\nThese are the original Dataframe column names:\\n')\n",
    "    display(data.columns)\n",
    "    #Standardize headers\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        cols.append(col.lower().replace(' ', '_'))\n",
    "    df.columns = cols\n",
    "    #Rounding up total claim amount and customer lifetime value columns to 2 decimals\n",
    "    df['total_claim_amount'] = df['total_claim_amount'].round(decimals = 2)\n",
    "    df['customer_lifetime_value'] = df['customer_lifetime_value'].round(decimals = 2)\n",
    "    #Data types\n",
    "    print('\\nThese are the data types for all columns (headers already standardized):\\n')\n",
    "    display(df.dtypes)\n",
    "    #Numerical and categorical columns\n",
    "    numerical = df.select_dtypes(include = np.number)\n",
    "    categorical = df.select_dtypes(include='object')\n",
    "    print('\\nThese are the numerical columns')\n",
    "    display(numerical)\n",
    "    print('These are the categorical columns')\n",
    "    display(categorical)\n",
    "    #Plots made with Seaborn\n",
    "    print('\\nThese are the graphs made with Seaborn library\\n')\n",
    "    fig, axes = plt.subplots(4,2,figsize=(20,20), dpi=300)\n",
    "    sns.histplot(data = numerical, x='customer_lifetime_value', ax = axes[0,0])\n",
    "    axes[0,0].set_xlabel('Customer Lifetime Value')\n",
    "    sns.histplot(data = numerical, x='income', ax = axes[0,1])\n",
    "    axes[0,1].set_xlabel('Income')\n",
    "    sns.histplot(data = numerical, x='monthly_premium_auto', ax = axes[1,0])\n",
    "    axes[1,0].set_xlabel('Monthly Premium Auto')\n",
    "    sns.histplot(data = numerical, x='months_since_last_claim', ax = axes[1,1])\n",
    "    axes[1,1].set_xlabel('Months Since Last Claim')\n",
    "    sns.histplot(data = numerical, x='months_since_policy_inception', ax = axes[2,0])\n",
    "    axes[2,0].set_xlabel('Months Since Policy Inception')\n",
    "    sns.histplot(data = numerical, x='number_of_open_complaints', ax = axes[2,1])\n",
    "    axes[2,1].set_xlabel('Number of Open Complaints')\n",
    "    sns.histplot(data = numerical, x='number_of_policies', ax = axes[3,0])\n",
    "    axes[3,0].set_xlabel('Number of Policies')\n",
    "    sns.histplot(data = numerical, x='total_claim_amount', ax = axes[3,1])\n",
    "    axes[3,1].set_xlabel('Total Claim Amount')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #Plots made with matplotlib\n",
    "    print('\\nThese are the histograms made in matplotlib')\n",
    "    fig, axes = plt.subplots(4,2,figsize=(20,20), dpi=300)\n",
    "    axes[0,0].hist(x=numerical['customer_lifetime_value'], bins=50)\n",
    "    axes[0,0].set_xlabel('Customer Lifetime Value')\n",
    "    axes[0,1].hist(x=numerical['income'], bins=50)\n",
    "    axes[0,1].set_xlabel('Income')\n",
    "    axes[1,0].hist(x=numerical['monthly_premium_auto'], bins=50)\n",
    "    axes[1,0].set_xlabel('Monthly Premium Auto')\n",
    "    axes[1,1].hist(x=numerical['months_since_last_claim'], bins=50)\n",
    "    axes[1,1].set_xlabel('Months Since Last Claim')\n",
    "    axes[2,0].hist(x=numerical['months_since_policy_inception'], bins=50)\n",
    "    axes[2,0].set_xlabel('Months Since Policy Inception')\n",
    "    axes[2,1].hist(x=numerical['number_of_open_complaints'], bins=50)\n",
    "    axes[2,1].set_xlabel('Number of Open Complaints')\n",
    "    axes[3,0].hist(x=numerical['number_of_policies'], bins=50)\n",
    "    axes[3,0].set_xlabel('Number of Policies')\n",
    "    axes[3,1].hist(x=numerical['total_claim_amount'], bins=50)\n",
    "    axes[3,1].set_xlabel('Total Claim Amount')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #Do the distributions for different numerical variables look like a normal distribution?\n",
    "    print('\\nDo the distributions for different numerical variables look like a normal distribution?')\n",
    "    sns.pairplot(numerical)\n",
    "    plt.show()\n",
    "    print('Far from it')\n",
    "    print('\\nWe will check Months since last claim and Months since policy inception as they look quite evently distributed')\n",
    "    fig, axes = plt.subplots(1,2,figsize=(15,5), dpi=200)\n",
    "    sns.boxplot(data = numerical, x='months_since_last_claim', ax = axes[0])\n",
    "    axes[0].set_xlabel('Months Since Last Claim')\n",
    "    sns.boxplot(data = numerical, x='months_since_policy_inception', ax = axes[1])\n",
    "    axes[1].set_xlabel('Months Since Policy Inception')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\nCheking how different the Income column is by including or excluding 0 income values')\n",
    "    income0excl = []\n",
    "    for i in df['income']:\n",
    "        if i>0:\n",
    "            income0excl.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    income_positive = pd.DataFrame (income0excl, columns = ['income'])\n",
    "    fig, axes = plt.subplots(1,2,figsize=(15,5), dpi=200)\n",
    "    sns.boxplot(data = df, x='income', ax=axes[0])\n",
    "    axes[0].set_xlabel('Income - including 0 values')\n",
    "    sns.boxplot(data = income_positive, x='income', ax=axes[1])\n",
    "    axes[1].set_xlabel('Income - excluding 0 values')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\nWe can also see the differences via histograms:')\n",
    "    fig, axes = plt.subplots(1,2,figsize=(15,5), dpi=200)\n",
    "    sns.histplot(data = df, x='income', ax = axes[0])\n",
    "    axes[0].set_xlabel('Income - including 0 values')\n",
    "    sns.histplot(data = income_positive, x='income', ax = axes[1])\n",
    "    axes[1].set_xlabel('Income - excluding 0 values')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\nWe will check the multicorrelation via matrix and heatmap')\n",
    "    correlations_matrix = numerical.corr()\n",
    "    display(correlations_matrix)\n",
    "    sns.heatmap(correlations_matrix, annot=True)\n",
    "    plt.show()\n",
    "    print('Total claim amount and monthly premium auto are the only values with a minimal correlation (0.63), so we will not drop any columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c162f-edce-40cc-abf6-2fecf79b213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lab_4(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a464ab4-0231-4358-8e38-b1cbd594a233",
   "metadata": {},
   "source": [
    "<h1>Lab | Customer Analysis Round 5<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c112885-8578-42a3-aca3-237d7c3d8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81857c60-7699-4a49-92ab-7404945b44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_5(df):\n",
    "    df = df.select_dtypes(include = np.number)\n",
    "    X = df.drop(['total_claim_amount'], axis=1)\n",
    "    y = df['monthly_premium_auto']\n",
    "    print('This is dataframe X')\n",
    "    display(X)\n",
    "    print('\\nThis is dataframe y')\n",
    "    display(y)\n",
    "    X_nrm = X.copy()\n",
    "    X_std = X.copy()\n",
    "    transformer = MinMaxScaler().fit(X_nrm)\n",
    "    x_normalized = transformer.transform(X_nrm)\n",
    "    x_normalized = pd.DataFrame(x_normalized, columns=X_nrm.columns)\n",
    "    print('\\nThis is X after normalization with MinMaxScaler')\n",
    "    display(x_normalized)\n",
    "    transformer2 = StandardScaler().fit(X_std)\n",
    "    x_standardized = transformer2.transform(X_std)\n",
    "    x_standardized = pd.DataFrame(x_standardized, columns=X_std.columns)\n",
    "    print('\\nThis is X after Standardization with StandardScaler')\n",
    "    display(x_standardized)\n",
    "    fig, axes = plt.subplots(7, 3, figsize=(15,15), dpi=500)\n",
    "\n",
    "    sns.histplot(data=X, x='customer_lifetime_value',ax=axes[0][0])\n",
    "    axes[0,0].set_xlabel('Customer Lifetime Value')\n",
    "    sns.histplot(data=X, x='income',ax=axes[1][0])\n",
    "    axes[1,0].set_xlabel('Income')\n",
    "    sns.histplot(data=X, x='monthly_premium_auto',ax=axes[2][0])\n",
    "    axes[2,0].set_xlabel('Monthly Premium Auto')\n",
    "    sns.histplot(data=X, x='months_since_last_claim',ax=axes[3][0])\n",
    "    axes[3,0].set_xlabel('Months Since Last Claim')\n",
    "    sns.histplot(data=X, x='months_since_policy_inception',ax=axes[4][0])\n",
    "    axes[4,0].set_xlabel('Months Since Policy Inception')\n",
    "    sns.histplot(data=X, x='number_of_open_complaints',ax=axes[5][0])\n",
    "    axes[5,0].set_xlabel('Number of Policies')\n",
    "    sns.histplot(data=X, x='number_of_policies',ax=axes[6][0])\n",
    "    axes[6,0].set_xlabel('Total Claim Amount')\n",
    "\n",
    "    sns.histplot(data=x_normalized, x='customer_lifetime_value',ax=axes[0][1])\n",
    "    axes[0,1].set_xlabel('Customer Lifetime Value\\nNormalized')\n",
    "    sns.histplot(data=x_normalized, x='income',ax=axes[1][1])\n",
    "    axes[1,1].set_xlabel('Income\\nNormalized')\n",
    "    sns.histplot(data=x_normalized, x='monthly_premium_auto',ax=axes[2][1])\n",
    "    axes[2,1].set_xlabel('Monthly Premium Auto\\nNormalized')\n",
    "    sns.histplot(data=x_normalized, x='months_since_last_claim',ax=axes[3][1])\n",
    "    axes[3,1].set_xlabel('Months Since Last Claim\\nNormalized')\n",
    "    sns.histplot(data=x_normalized, x='months_since_policy_inception',ax=axes[4][1])\n",
    "    axes[4,1].set_xlabel('Months Since Policy Inception\\nNormalized')\n",
    "    sns.histplot(data=x_normalized, x='number_of_open_complaints',ax=axes[5][1])\n",
    "    axes[5,1].set_xlabel('Number of Policies\\nNormalized')\n",
    "    sns.histplot(data=x_normalized, x='number_of_policies',ax=axes[6][1])\n",
    "    axes[6,1].set_xlabel('Total Claim Amount\\nNormalized')\n",
    "\n",
    "    sns.histplot(data=x_standardized, x='customer_lifetime_value',ax=axes[0][2])\n",
    "    axes[0,2].set_xlabel('Customer Lifetime Value\\nStandardized')\n",
    "    sns.histplot(data=x_standardized, x='income',ax=axes[1][2])\n",
    "    axes[1,2].set_xlabel('Incomen\\nStandardized')\n",
    "    sns.histplot(data=x_standardized, x='monthly_premium_auto',ax=axes[2][2])\n",
    "    axes[2,2].set_xlabel('Monthly Premium Auton\\nStandardized')\n",
    "    sns.histplot(data=x_standardized, x='months_since_last_claim',ax=axes[3][2])\n",
    "    axes[3,2].set_xlabel('Months Since Last Claim\\nStandardized')\n",
    "    sns.histplot(data=x_standardized, x='months_since_policy_inception',ax=axes[4][2])\n",
    "    axes[4,2].set_xlabel('Months Since Policy Inception\\nStandardized')\n",
    "    sns.histplot(data=x_standardized, x='number_of_open_complaints',ax=axes[5][2])\n",
    "    axes[5,2].set_xlabel('Number of Policies\\nStandardized')\n",
    "    sns.histplot(data=x_standardized, x='number_of_policies',ax=axes[6][2])\n",
    "    axes[6,2].set_xlabel('Total Claim Amount\\nStandardized')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605b49c-3dc3-4143-9d8f-f07f5344da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_5(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480a05e-055e-4c1c-b042-c3a086bd09c8",
   "metadata": {},
   "source": [
    "<h1>Lab | Customer Analysis Round 6<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acd8df-ab35-49df-88b4-b8a0df55a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a3928-ed03-4b42-bc7f-8ebb4cf706b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_6(df):\n",
    "    df = df.select_dtypes(include = np.number)\n",
    "    d2 = df.copy()\n",
    "    X = df.drop(['total_claim_amount'], axis=1)\n",
    "    y = df['total_claim_amount']\n",
    "    \n",
    "    X.describe().T\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=86)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    X_train.head()\n",
    "    y_train.head()\n",
    "    print('\\nLinear regression, X and y train / test\\n')\n",
    "    print('This is the shape of X train: \\n', X_train.shape)\n",
    "    print('This is the shape of X test: \\n', X_test.shape)\n",
    "    print('This is the shape of y train: \\n', y_train.shape)\n",
    "    print('This is the shape of y test: \\n', y_test.shape)\n",
    "    print()\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "    y_pred_train = lm.predict(X_train)\n",
    "    y_pred_test = lm.predict(X_test)\n",
    "    print('\\nError tests\\n')\n",
    "    print(f'R2 train = {r2_score(y_train, y_pred_train):.4f}')\n",
    "    print(f'R2 test = {r2_score(y_test, y_pred_test):.4f}')\n",
    "    print()\n",
    "    print(f'RMSE train = {(np.sqrt(mean_squared_error(y_train,y_pred_train))):.4f}')\n",
    "    print(f'RMSE test = {(np.sqrt(mean_squared_error(y_test,y_pred_test))):.4f}')\n",
    "    print()\n",
    "    print (f'MAE train = {(metrics.mean_absolute_error(y_train, y_pred_train)):.4f}')\n",
    "    print (f'MAE test = {(metrics.mean_absolute_error(y_test, y_pred_test)):.4f}')\n",
    "    print()\n",
    "    print (f'MSE train = {(metrics.mean_squared_error(y_train, y_pred_train)):.4f}')\n",
    "    print (f'MAE test = {(metrics.mean_squared_error(y_test, y_pred_test)):.4f}')\n",
    "    print()\n",
    "    \n",
    "    #POWER TRANSFORMER\n",
    "    transformer1 = PowerTransformer().fit(d2)\n",
    "    dpt = transformer1.transform(d2)\n",
    "    dpt = pd.DataFrame(dpt, columns=d2.columns)\n",
    "    print('\\nThis is the dataframe after using PowerTransformer')\n",
    "    display(dpt)\n",
    "    ypt = dpt['total_claim_amount']\n",
    "    Xpt = dpt.drop(['total_claim_amount'], axis=1)\n",
    "    Xpt_train, Xpt_test, ypt_train, ypt_test = train_test_split(Xpt, ypt, test_size=0.2, random_state=86)\n",
    "    print('\\nLinear regression, X and y train / test\\n')\n",
    "    print('This is the shape of X train: \\n', Xpt_train.shape)\n",
    "    print('This is the shape of X test: \\n', Xpt_test.shape)\n",
    "    print('This is the shape of y train: \\n', ypt_train.shape)\n",
    "    print('This is the shape of y test: \\n', ypt_test.shape)\n",
    "    print()\n",
    "    lmpt = LinearRegression()\n",
    "    lmpt.fit(Xpt_train,ypt_train)\n",
    "    ypt_pred_train = lmpt.predict(Xpt_train)\n",
    "    ypt_pred_test = lmpt.predict(Xpt_test)\n",
    "    print('\\nError tests after applying PowerTransformer to the data:\\n')\n",
    "    print(f'R2 train = {r2_score(ypt_train, ypt_pred_train):.4f}')\n",
    "    print(f'R2 test = {r2_score(ypt_test, ypt_pred_test):.4f}')\n",
    "    print()\n",
    "    print(f'RMSE train = {(np.sqrt(mean_squared_error(ypt_train,ypt_pred_train))):.4f}')\n",
    "    print(f'RMSE test = {(np.sqrt(mean_squared_error(ypt_test,ypt_pred_test))):.4f}')\n",
    "    print()\n",
    "    print (f'MAE train = {(metrics.mean_absolute_error(ypt_train, ypt_pred_train)):.4f}')\n",
    "    print (f'MAE test = {(metrics.mean_absolute_error(ypt_test, ypt_pred_test)):.4f}')\n",
    "    print()\n",
    "    print (f'MSE train = {(metrics.mean_squared_error(ypt_train, ypt_pred_train)):.4f}')\n",
    "    print (f'MAE test = {(metrics.mean_squared_error(ypt_test, ypt_pred_test)):.4f}')\n",
    "    \n",
    "    #MinMaxScaler (Normalized)\n",
    "    transformer2 = MinMaxScaler().fit(dpt)\n",
    "    dnrm = transformer2.transform(dpt)\n",
    "    dnrm = pd.DataFrame(dnrm, columns=d2.columns)\n",
    "    ynrm = dnrm['total_claim_amount']\n",
    "    Xnrm = dnrm.drop(['total_claim_amount'], axis=1)\n",
    "    print('\\nThis is the dataframe after applying MinMaxScaler to the PowerTransfored data:')\n",
    "    display(dnrm)\n",
    "    Xnrm_train, Xnrm_test, ynrm_train, ynrm_test = train_test_split(Xnrm, ynrm, test_size=0.2, random_state=86)\n",
    "    print('\\nLinear regression, X and y train / test\\n')\n",
    "    print('This is the shape of X train: \\n', Xnrm_train.shape)\n",
    "    print('This is the shape of X test: \\n', Xnrm_test.shape)\n",
    "    print('This is the shape of y train: \\n', ynrm_train.shape)\n",
    "    lmnrm = LinearRegression()\n",
    "    lmnrm.fit(Xnrm_train,ynrm_train)\n",
    "    ynrm_pred_train = lmpt.predict(Xnrm_train)\n",
    "    ynrm_pred_test = lmpt.predict(Xnrm_test)\n",
    "    print('\\nError tests after applying Standard Scaler to the Power Transformed dataset:\\n')\n",
    "    print(f'R2 train = {r2_score(ynrm_train, ynrm_pred_train):.4f}')\n",
    "    print(f'R2 test = {r2_score(ynrm_test, ynrm_pred_test):.4f}')\n",
    "    print()\n",
    "    print(f'RMSE train = {(np.sqrt(mean_squared_error(ynrm_train,ynrm_pred_train))):.4f}')\n",
    "    print(f'RMSE test = {(np.sqrt(mean_squared_error(ynrm_test,ynrm_pred_test))):.4f}')\n",
    "    print()\n",
    "    print (f'MAE train = {(metrics.mean_absolute_error(ynrm_train, ynrm_pred_train)):.4f}')\n",
    "    print (f'MAE test = {(metrics.mean_absolute_error(ynrm_test, ynrm_pred_test)):.4f}')\n",
    "    print()\n",
    "    print (f'MSE train = {(metrics.mean_squared_error(ynrm_train, ynrm_pred_train)):.4f}')\n",
    "    print (f'MAE test = {(metrics.mean_squared_error(ynrm_test, ynrm_pred_test)):.4f}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5084b4-53b6-48fc-9868-8c39567ca147",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_6(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95786ff2-3cf3-4967-8f6f-ddbf1c05b168",
   "metadata": {},
   "source": [
    "<h1>Data results<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c694c-0c15-46cd-8481-0ec0d201b481",
   "metadata": {},
   "source": [
    "We can see that applying the standarization has reduced the errors but also the R2 so the model performance is worse. Applying the normalization over this transformed data has completely offset R2 value, so the model is not operative at all after this second transformation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
